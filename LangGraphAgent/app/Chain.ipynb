{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chain\n",
    "## Review\n",
    "\n",
    "En el archivo Simple_Graph se contruyó un grafico simple con nodos, edges normales y edges condicionales\n",
    "\n",
    "# Objetivo de este archivo\n",
    "\n",
    "Ahora se contruirá una cadena simple que combine 4 conceptos claves:\n",
    "\n",
    "* Usar mensajes de chat como \"estado\" para el grafico\n",
    "* Usar modelos de chat en los \"nodos\" del grafico\n",
    "* Enlazar \"Tools\" a nuestro modelo de chat\n",
    "* Ejecutar llamadas a las \"tools en el grafico\""
   ],
   "id": "cb9c51234cdc7de3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T13:17:48.243156Z",
     "start_time": "2025-02-11T13:17:45.706192Z"
    }
   },
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Mensajes [Messages]\n",
    "Los modelos de chat pueden usar \"messages\", los cuales capturan los diferentes roles dentro de una conversasión\n",
    "LangChain soporta varios tipos de \"messages\", incluyendo HumanMessage, AIMessage, SystemMessage, y ToolMessage\n",
    "\n",
    "Estos representan mensajes enviados por el usuario, por el modelo de chat para que el modelo indique un comportamiento y una llamada a alguna herramienta\n",
    "\n",
    "Crearemos una lista de mensajes\n",
    "Cada mensaje puede incluir alguna de las siguientes cosas:\n",
    "* [content] - Es el contenido del mensaje\n",
    "* [name] - Opcionalmente un mensaje del autor\n",
    "* [response_metada] - Opcionalmente, un diccionario de metadatos (Ej: En ocaciones completado por el proveedor del modelo para AIMessages)"
   ],
   "id": "4fcadd52361dec8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:17:50.270650Z",
     "start_time": "2025-02-11T13:17:50.013720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.extend([HumanMessage(content=f\"Yes, that´s right.\", name =\"Lance\")])\n",
    "messages.extend([AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\")])\n",
    "messages.extend([HumanMessage(content=f\"I want to learn about teh best place to see Orcas in the US\",name =\"Lance\")])\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ],
   "id": "817a02bf48982a83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that´s right.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about teh best place to see Orcas in the US\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# Modelos de Chat\n",
    "Los modelos de chat pueden usar una secuencia de mensajes como entarda y admitir roles en los mensajes como se mencionó en la sección anterior"
   ],
   "id": "7ebac4ea4909e79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:17:57.988228Z",
     "start_time": "2025-02-11T13:17:56.030598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from general_conf.imports import *\n",
    "load_dotenv(find_dotenv())\n",
    "print(\"Ingresando la APIKEY\")\n",
    "\n"
   ],
   "id": "55aa941bffdcf51d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingresando la APIKEY\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Podemos cargar el modelo de chat e invocarlo con \"invoke\" con la lista de mensajes\n",
    "Se puede ver que el resultado es un AIMessage con \"response_metada\" especificos"
   ],
   "id": "1aebd8b7327b2064"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T18:21:55.850691Z",
     "start_time": "2025-02-07T18:21:53.624063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ],
   "id": "2219b0e687e9fd7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T18:22:45.612602Z",
     "start_time": "2025-02-07T18:22:45.604544Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "c9a45843033df33c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One of the best places to see Orcas in the US is in the Pacific Northwest, specifically in the waters around the San Juan Islands in Washington State. The area is known for its resident Orca population, called the Southern Resident killer whales. You can take whale-watching tours from places like Seattle, Anacortes, or Friday Harbor to increase your chances of spotting these magnificent animals in their natural habitat. Additionally, you may also see Orcas in other coastal regions of the US, such as Alaska, Oregon, and California, but the San Juan Islands are particularly renowned for Orca sightings.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 67, 'total_tokens': 189, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-33e80041-da3e-4719-9ba3-9dd5eea8f319-0', usage_metadata={'input_tokens': 67, 'output_tokens': 122, 'total_tokens': 189, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T18:25:09.165252Z",
     "start_time": "2025-02-07T18:25:09.158681Z"
    }
   },
   "cell_type": "code",
   "source": "result.response_metadata",
   "id": "57ed9f4d279981e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 122,\n",
       "  'prompt_tokens': 67,\n",
       "  'total_tokens': 189,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TOOLS \n",
    "Las herramientas o \"tools\" son serán siempr utiles cuando se quiera que nuestro sistema de agentes interactue con sistemas externos\n",
    "Estos sitemas externos como la API's, amenudo requieren un esquema de entrada particular en lugar del leguaje natural\n",
    "\n",
    "Cuando por ejemplo enlazamos una API, como herramienta, le damos al modelo conocimiento del esquema de la entrada requerida\n",
    "\n",
    "El modelo decidirá a que herramienta llamar basandose en la entrada del lengaje natural de usuario, y devolverá una salida que se adihera al esquema de la herramienta\n",
    "\n",
    "Muchos proveedores LLM soportan la llamada a herramientas y la interfaz de llamada a herramientas en LangChain es sencilla. \n",
    " \n",
    "Puedes simplemente pasar cualquier 'función' de Python a 'ChatModel.bind_tools(function)'."
   ],
   "id": "9738bbf0f20e107b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T18:58:20.112968Z",
     "start_time": "2025-02-07T18:58:20.100964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def multiply(a:int, b:int) -> int:\n",
    "    \"\"\"\n",
    "    Multply a and b\n",
    "    Args:\n",
    "        a: first number\n",
    "        b: second number \n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ],
   "id": "744bf3d4f8c4a7e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Si pasaramos una entrada como por ejemplo \"Cuanto es 2 multiplicado por 3\", veriamos la llamada a la herramienta \n",
    "La llamada a la herramienta tiene argumentos específicos que coinciden con el esquema de entrada de nuestra función junto con el nombre de la función a llamar.\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```\n",
    "\n"
   ],
   "id": "17aa3d07f44a08a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T19:01:51.359613Z",
     "start_time": "2025-02-07T19:01:50.244448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"Cuanto es 2 multiplicado por 3\", name=\"Lance\")])\n",
    "tool_call"
   ],
   "id": "3501cbb78b57be7c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Lmx65w7Zz7KJUg367suHhesS', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 74, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3abe8f02-7dba-4a83-b680-7b9e7366a9d4-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_Lmx65w7Zz7KJUg367suHhesS', 'type': 'tool_call'}], usage_metadata={'input_tokens': 74, 'output_tokens': 33, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T19:02:36.819666Z",
     "start_time": "2025-02-07T19:02:36.814160Z"
    }
   },
   "cell_type": "code",
   "source": "tool_call.additional_kwargs['tool_calls']",
   "id": "93f13917d9de1d65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_Lmx65w7Zz7KJUg367suHhesS',\n",
       "  'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'},\n",
       "  'type': 'function'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Usar mensajes como un estado del grafico\n",
    "Con todos estos fundamentos podemos usar \"message\" en el estado de nuestros graficos\n",
    "Definiremos nuestro estado \"MessageState como un TypedDict con una sola clave \"message\"\n",
    "\"message\" es simplemente una lista de mensajes, como se definieron anteriormente, como Ej: HumanMessage\n"
   ],
   "id": "522faa2b8bfd28e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T19:38:37.995329Z",
     "start_time": "2025-02-07T19:38:37.979797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    message: list[AnyMessage]\n",
    "    "
   ],
   "id": "251c4400a3487062",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Reductores\n",
    "\n",
    "¡Ahora tenemos un pequeño problema!\n",
    "\n",
    "A medida que se ejecuta nuestro gráfico, queremos agregar mensajes a nuestra clave de estado de \"messages\".\n",
    "Pero, como comentamos, cada nodo también anulará el valor del estado anterior.\n",
    "## Las funciones reductoras abordan esto.\n",
    "Nos permiten especificar cómo se realizan las actualizaciones de estado.\n",
    "Si no se especifica explícitamente ninguna función reductora, se supone que todas las actualizaciones de esa clave deben anularla.\n",
    "Como queremos agregar \"messages\", ¡podemos usar un reductor [add_messages] prediseñado!\n",
    "Esto garantiza que las actualizaciones de estado que envíe al gráfico se agreguen a la lista de mensajes existente.\n",
    "Anotamos (a través de Annotated) nuestra clave con una función reductora como metadatos."
   ],
   "id": "be87ca217b38d807"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T19:39:06.186604Z",
     "start_time": "2025-02-07T19:39:06.182505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    message: Annotated[list[AnyMessage], add_messages]\n",
    "    "
   ],
   "id": "dbcd1354072d5ecb",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dado que es muy común tener una lista de mensajes en estado gráfico, LangGraph tiene un [`MessagesState`] precompilado.\n",
    "\n",
    "Se define `MessagesState`:\n",
    "\n",
    "* Con una clave `messages` única precompilada\n",
    "* Esta es una lista de objetos `AnyMessage`\n",
    "* Utiliza el reductor `add_messages`\n",
    "\n",
    "Normalmente utilizaremos `MessagesState` porque es menos detallado que definir un `TypedDict` personalizado, como se muestra arriba."
   ],
   "id": "8db2a0fd7c9a3ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T19:39:09.150998Z",
     "start_time": "2025-02-07T19:39:09.140519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import MessagesState\n",
    "class MessageState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built\n",
    "    pass"
   ],
   "id": "6213de708d932a43",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para profundizar un poco más, podemos ver cómo funciona el reductor `add_messages` de forma aislada.",
   "id": "bef9879ec45f72ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T19:39:11.449579Z",
     "start_time": "2025-02-07T19:39:11.434514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initial state\n",
    "initial_messages =[AIMessage(content=\"Hola, cómo puedo ayudarte?\", name=\"Model\"), \n",
    "                   HumanMessage(content=\"Estoy buscando información de biologia marina\", name=\"Lance\")]\n",
    "# New Message to add\n",
    "new_message = AIMessage(content=\"Claro, puedo ayudarte con eso. En que estás interesado especificamente?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "\n",
    "add_messages(initial_messages, new_message)"
   ],
   "id": "a874b2662738fd62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hola, cómo puedo ayudarte?', additional_kwargs={}, response_metadata={}, name='Model', id='01796b4e-0fd2-4be6-a812-000ccd402851'),\n",
       " HumanMessage(content='Estoy buscando información de biologia marina', additional_kwargs={}, response_metadata={}, name='Lance', id='434a3fcd-e6ca-4ae8-a790-bc45de56608c'),\n",
       " AIMessage(content='Claro, puedo ayudarte con eso. En que estás interesado especificamente?', additional_kwargs={}, response_metadata={}, name='Model', id='25043387-2a08-4910-bf89-2bc5cfdd5841')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Nuestro Grafico\n",
    "Ahora intentemos utilizar MessagesState en un grafico"
   ],
   "id": "8dda39b0fd5f071"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T20:10:29.319947Z",
     "start_time": "2025-02-07T20:10:29.181842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# State\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed  beyond messages, which is pre-built\n",
    "    pass\n",
    "\n",
    "# Nodo\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\"\"\"\n",
    "# Nodo\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\"\"\"\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ],
   "id": "c0c787779cc5b3a0",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T20:10:33.913069Z",
     "start_time": "2025-02-07T20:10:32.944174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hola\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()\n",
    "    "
   ],
   "id": "2c6505e64bb2a4be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hola\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "¡Hola! ¿Cómo estás? ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T20:10:36.934504Z",
     "start_time": "2025-02-07T20:10:36.919199Z"
    }
   },
   "cell_type": "code",
   "source": "messages",
   "id": "242a58dd9a12d3b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hola', additional_kwargs={}, response_metadata={}, id='5c3f6e7b-7211-4127-881c-91c0e5108157'),\n",
       "  AIMessage(content='¡Hola! ¿Cómo estás? ¿En qué puedo ayudarte hoy?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 8, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-802824d0-080c-4629-bbb8-b27610ec94e5-0', usage_metadata={'input_tokens': 8, 'output_tokens': 17, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "El LLM elige utilizar una herramienta cuando determina que la entrada o la tarea requiere la funcionalidad proporcionada por esa herramienta.",
   "id": "78030c53049b67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T20:10:41.995622Z",
     "start_time": "2025-02-07T20:10:41.192656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Puedes multiplicar 2 por 8\")})\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "id": "30b37f84f3801875",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Puedes multiplicar 2 por 8\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Sí, 2 por 8 es igual a 16.\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T20:10:44.341115Z",
     "start_time": "2025-02-07T20:10:44.335997Z"
    }
   },
   "cell_type": "code",
   "source": "messages",
   "id": "ef2b3b0e96b52e85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Puedes multiplicar 2 por 8', additional_kwargs={}, response_metadata={}, id='446f29c5-d3ae-42ae-85da-3b0de7e39f39'),\n",
       "  AIMessage(content='Sí, 2 por 8 es igual a 16.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 17, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-28602c5e-32ee-4998-80ac-144e8f5f5a32-0', usage_metadata={'input_tokens': 17, 'output_tokens': 15, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
